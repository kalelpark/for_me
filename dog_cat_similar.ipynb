{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59f2dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "path = []\n",
    "dataset = []\n",
    "label = []\n",
    "\n",
    "for dirname, _, filenames in os.walk('./Cat_Dog'):\n",
    "    for filename in filenames:\n",
    "        if '.jpg' in filename:\n",
    "            file_path = dirname + '/' + filename\n",
    "            path.append(file_path)\n",
    "            \n",
    "            if 'training_set' in file_path:\n",
    "                dataset.append('train')\n",
    "            elif 'test_set' in file_path:\n",
    "                dataset.append('test')\n",
    "            else:\n",
    "                dataset.append('N/A')\n",
    "            \n",
    "            if 'dogs' in file_path:\n",
    "                label.append('dog')\n",
    "            elif 'cat' in file_path:\n",
    "                label.append('cat')\n",
    "            else:\n",
    "                label.append('N/A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97135607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>dataset</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Cat_Dog\\test_set\\test_set\\cats/cat.4001.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Cat_Dog\\test_set\\test_set\\cats/cat.4002.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Cat_Dog\\test_set\\test_set\\cats/cat.4003.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Cat_Dog\\test_set\\test_set\\cats/cat.4004.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Cat_Dog\\test_set\\test_set\\cats/cat.4005.jpg</td>\n",
       "      <td>test</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path dataset label\n",
       "0  ./Cat_Dog\\test_set\\test_set\\cats/cat.4001.jpg    test   cat\n",
       "1  ./Cat_Dog\\test_set\\test_set\\cats/cat.4002.jpg    test   cat\n",
       "2  ./Cat_Dog\\test_set\\test_set\\cats/cat.4003.jpg    test   cat\n",
       "3  ./Cat_Dog\\test_set\\test_set\\cats/cat.4004.jpg    test   cat\n",
       "4  ./Cat_Dog\\test_set\\test_set\\cats/cat.4005.jpg    test   cat"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 300)\n",
    "data_df = pd.DataFrame({'path' : path, 'dataset' : dataset, 'label' : label})\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53dac9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 validated image filenames belonging to 2 classes.\n",
      "Found 1601 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_df = data_df[data_df['dataset'] == 'train']\n",
    "test_df = data_df[data_df['dataset'] == 'test']\n",
    "\n",
    "tr_df, val_df = train_test_split(train_df, test_size = 0.2, stratify = train_df['label'], random_state = 256)\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "tr_generator = ImageDataGenerator(rescale = 1/255)\n",
    "train_flow_gen = tr_generator.flow_from_dataframe(dataframe= train_df,\n",
    "                                                  x_col = 'path',\n",
    "                                                  y_col = 'label',\n",
    "                                                  target_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  batch_size = BATCH_SIZE,\n",
    "                                                  shuffle = True)\n",
    "\n",
    "val_generator = ImageDataGenerator(rescale = 1/255)\n",
    "valid_flow_gen = val_generator.flow_from_dataframe(dataframe= val_df,\n",
    "                                                   x_col = 'path',\n",
    "                                                   y_col = 'label',\n",
    "                                                   target_size= (IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                                   class_mode = 'categorical',\n",
    "                                                   batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07cdb4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.70980394, 0.64705884, 0.58431375],\n",
       "          [0.7411765 , 0.6784314 , 0.61960787],\n",
       "          [0.70980394, 0.64705884, 0.5882353 ],\n",
       "          ...,\n",
       "          [0.6784314 , 0.6392157 , 0.6       ],\n",
       "          [0.6862745 , 0.64705884, 0.60784316],\n",
       "          [0.68235296, 0.6431373 , 0.6039216 ]],\n",
       " \n",
       "         [[0.49411768, 0.43137258, 0.36862746],\n",
       "          [0.5529412 , 0.4901961 , 0.43137258],\n",
       "          [0.6156863 , 0.5529412 , 0.49411768],\n",
       "          ...,\n",
       "          [0.6784314 , 0.6392157 , 0.6       ],\n",
       "          [0.6862745 , 0.64705884, 0.60784316],\n",
       "          [0.68235296, 0.6431373 , 0.6039216 ]],\n",
       " \n",
       "         [[0.7137255 , 0.6509804 , 0.5882353 ],\n",
       "          [0.69411767, 0.6313726 , 0.57254905],\n",
       "          [0.69803923, 0.63529414, 0.5764706 ],\n",
       "          ...,\n",
       "          [0.6784314 , 0.6392157 , 0.6       ],\n",
       "          [0.6862745 , 0.64705884, 0.60784316],\n",
       "          [0.68235296, 0.6431373 , 0.6039216 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.5686275 , 0.45882356, 0.3647059 ],\n",
       "          [0.5882353 , 0.4784314 , 0.38431376],\n",
       "          [0.5764706 , 0.4666667 , 0.37254903],\n",
       "          ...,\n",
       "          [0.5529412 , 0.38431376, 0.30980393],\n",
       "          [0.5647059 , 0.39607847, 0.32156864],\n",
       "          [0.5568628 , 0.38823533, 0.3137255 ]],\n",
       " \n",
       "         [[0.59607846, 0.48627454, 0.3921569 ],\n",
       "          [0.5764706 , 0.4666667 , 0.37254903],\n",
       "          [0.56078434, 0.45098042, 0.35686275],\n",
       "          ...,\n",
       "          [0.5529412 , 0.38431376, 0.30980393],\n",
       "          [0.5686275 , 0.40000004, 0.3254902 ],\n",
       "          [0.5647059 , 0.39607847, 0.32156864]],\n",
       " \n",
       "         [[0.5764706 , 0.4666667 , 0.37254903],\n",
       "          [0.57254905, 0.46274513, 0.36862746],\n",
       "          [0.5647059 , 0.454902  , 0.36078432],\n",
       "          ...,\n",
       "          [0.5529412 , 0.38431376, 0.30980393],\n",
       "          [0.57254905, 0.4039216 , 0.32941177],\n",
       "          [0.57254905, 0.4039216 , 0.32941177]]],\n",
       " \n",
       " \n",
       "        [[[0.05882353, 0.05490196, 0.        ],\n",
       "          [0.05882353, 0.05490196, 0.        ],\n",
       "          [0.06666667, 0.05490196, 0.        ],\n",
       "          ...,\n",
       "          [0.26666668, 0.22352943, 0.09803922],\n",
       "          [0.28235295, 0.2392157 , 0.1137255 ],\n",
       "          [0.29411766, 0.24313727, 0.11764707]],\n",
       " \n",
       "         [[0.12156864, 0.11764707, 0.03529412],\n",
       "          [0.1137255 , 0.10980393, 0.02745098],\n",
       "          [0.10588236, 0.09411766, 0.02745098],\n",
       "          ...,\n",
       "          [0.20784315, 0.16470589, 0.03921569],\n",
       "          [0.23529413, 0.18431373, 0.0509804 ],\n",
       "          [0.22352943, 0.17254902, 0.04705883]],\n",
       " \n",
       "         [[0.45882356, 0.454902  , 0.37254903],\n",
       "          [0.42352945, 0.41960788, 0.3372549 ],\n",
       "          [0.3647059 , 0.3529412 , 0.28627452],\n",
       "          ...,\n",
       "          [0.25882354, 0.20784315, 0.07450981],\n",
       "          [0.25490198, 0.20000002, 0.0627451 ],\n",
       "          [0.23137257, 0.17254902, 0.04313726]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.37647063, 0.12156864, 0.0509804 ],\n",
       "          [0.3019608 , 0.07450981, 0.        ],\n",
       "          [0.28235295, 0.09411766, 0.00784314],\n",
       "          ...,\n",
       "          [0.15294118, 0.15686275, 0.08627451],\n",
       "          [0.07843138, 0.08235294, 0.01176471],\n",
       "          [0.10196079, 0.10588236, 0.03529412]],\n",
       " \n",
       "         [[0.34117648, 0.07843138, 0.01176471],\n",
       "          [0.34117648, 0.10196079, 0.02745098],\n",
       "          [0.3137255 , 0.1137255 , 0.03137255],\n",
       "          ...,\n",
       "          [0.07058824, 0.07450981, 0.00392157],\n",
       "          [0.0627451 , 0.06666667, 0.        ],\n",
       "          [0.10588236, 0.10980393, 0.03921569]],\n",
       " \n",
       "         [[0.34117648, 0.07843138, 0.01176471],\n",
       "          [0.34117648, 0.10196079, 0.02745098],\n",
       "          [0.3137255 , 0.1137255 , 0.03137255],\n",
       "          ...,\n",
       "          [0.08235294, 0.08627451, 0.01568628],\n",
       "          [0.07450981, 0.07843138, 0.00784314],\n",
       "          [0.10588236, 0.10980393, 0.03921569]]],\n",
       " \n",
       " \n",
       "        [[[0.10196079, 0.20000002, 0.1764706 ],\n",
       "          [0.10196079, 0.20000002, 0.1764706 ],\n",
       "          [0.09411766, 0.19215688, 0.16862746],\n",
       "          ...,\n",
       "          [0.7372549 , 0.9333334 , 0.9294118 ],\n",
       "          [0.7019608 , 0.882353  , 0.8745099 ],\n",
       "          [0.7019608 , 0.882353  , 0.882353  ]],\n",
       " \n",
       "         [[0.09411766, 0.19215688, 0.16862746],\n",
       "          [0.09803922, 0.19607845, 0.17254902],\n",
       "          [0.09803922, 0.19607845, 0.17254902],\n",
       "          ...,\n",
       "          [0.54509807, 0.7490196 , 0.7411765 ],\n",
       "          [0.5137255 , 0.7019608 , 0.7019608 ],\n",
       "          [0.52156866, 0.70980394, 0.70980394]],\n",
       " \n",
       "         [[0.08627451, 0.19215688, 0.16470589],\n",
       "          [0.09019608, 0.19607845, 0.16862746],\n",
       "          [0.09019608, 0.19607845, 0.16862746],\n",
       "          ...,\n",
       "          [0.5019608 , 0.7137255 , 0.72156864],\n",
       "          [0.4666667 , 0.6666667 , 0.67058825],\n",
       "          [0.45098042, 0.654902  , 0.64705884]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.02745098, 0.03529412, 0.01568628],\n",
       "          [0.03137255, 0.03921569, 0.01960784],\n",
       "          [0.04313726, 0.0627451 , 0.03921569],\n",
       "          ...,\n",
       "          [0.02745098, 0.07058824, 0.03921569],\n",
       "          [0.01176471, 0.0509804 , 0.01568628],\n",
       "          [0.03137255, 0.0509804 , 0.03529412]],\n",
       " \n",
       "         [[0.03137255, 0.03529412, 0.01568628],\n",
       "          [0.02745098, 0.03529412, 0.01568628],\n",
       "          [0.03529412, 0.05490196, 0.03137255],\n",
       "          ...,\n",
       "          [0.03137255, 0.07843138, 0.03921569],\n",
       "          [0.01568628, 0.05490196, 0.01960784],\n",
       "          [0.03137255, 0.0509804 , 0.03529412]],\n",
       " \n",
       "         [[0.03137255, 0.03529412, 0.01568628],\n",
       "          [0.02745098, 0.03137255, 0.01176471],\n",
       "          [0.03137255, 0.0509804 , 0.02745098],\n",
       "          ...,\n",
       "          [0.03529412, 0.08235294, 0.04313726],\n",
       "          [0.02352941, 0.0627451 , 0.02745098],\n",
       "          [0.03137255, 0.0509804 , 0.03529412]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.2509804 , 0.16862746, 0.10196079],\n",
       "          [0.24705884, 0.16470589, 0.09803922],\n",
       "          [0.25882354, 0.1764706 , 0.10980393],\n",
       "          ...,\n",
       "          [0.27058825, 0.1764706 , 0.13725491],\n",
       "          [0.2784314 , 0.18431373, 0.14509805],\n",
       "          [0.2627451 , 0.16862746, 0.12941177]],\n",
       " \n",
       "         [[0.2509804 , 0.16862746, 0.10196079],\n",
       "          [0.24705884, 0.16470589, 0.09803922],\n",
       "          [0.25490198, 0.17254902, 0.10588236],\n",
       "          ...,\n",
       "          [0.26666668, 0.17254902, 0.13333334],\n",
       "          [0.27450982, 0.18039216, 0.14117648],\n",
       "          [0.2627451 , 0.16862746, 0.12941177]],\n",
       " \n",
       "         [[0.24705884, 0.16470589, 0.09803922],\n",
       "          [0.24313727, 0.16078432, 0.09411766],\n",
       "          [0.25490198, 0.17254902, 0.10588236],\n",
       "          ...,\n",
       "          [0.27450982, 0.16862746, 0.1254902 ],\n",
       "          [0.2784314 , 0.17254902, 0.12941177],\n",
       "          [0.27058825, 0.16470589, 0.12156864]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.3254902 , 0.20000002, 0.11764707],\n",
       "          [0.40000004, 0.27450982, 0.19215688],\n",
       "          [0.39607847, 0.27058825, 0.18823531],\n",
       "          ...,\n",
       "          [0.33333334, 0.21176472, 0.13333334],\n",
       "          [0.3529412 , 0.23137257, 0.15294118],\n",
       "          [0.32156864, 0.20000002, 0.12156864]],\n",
       " \n",
       "         [[0.37647063, 0.2509804 , 0.16862746],\n",
       "          [0.3921569 , 0.26666668, 0.18431373],\n",
       "          [0.36862746, 0.24313727, 0.16078432],\n",
       "          ...,\n",
       "          [0.34509805, 0.21568629, 0.14117648],\n",
       "          [0.3803922 , 0.2509804 , 0.1764706 ],\n",
       "          [0.34901962, 0.21960786, 0.14509805]],\n",
       " \n",
       "         [[0.37647063, 0.2509804 , 0.16862746],\n",
       "          [0.3921569 , 0.26666668, 0.18431373],\n",
       "          [0.36862746, 0.24313727, 0.16078432],\n",
       "          ...,\n",
       "          [0.34901962, 0.21960786, 0.14509805],\n",
       "          [0.3803922 , 0.2509804 , 0.1764706 ],\n",
       "          [0.34901962, 0.21960786, 0.14509805]]],\n",
       " \n",
       " \n",
       "        [[[0.9450981 , 0.95294124, 0.94117653],\n",
       "          [0.92549026, 0.9215687 , 0.90196085],\n",
       "          [0.89019614, 0.8745099 , 0.83921576],\n",
       "          ...,\n",
       "          [0.8862746 , 0.8470589 , 0.83921576],\n",
       "          [0.8588236 , 0.8196079 , 0.8117648 ],\n",
       "          [0.90196085, 0.86274517, 0.854902  ]],\n",
       " \n",
       "         [[0.98823535, 0.9921569 , 0.9725491 ],\n",
       "          [0.7254902 , 0.72156864, 0.7019608 ],\n",
       "          [0.69411767, 0.6784314 , 0.6431373 ],\n",
       "          ...,\n",
       "          [0.75294125, 0.70980394, 0.69411767],\n",
       "          [0.7960785 , 0.75294125, 0.7294118 ],\n",
       "          [0.8313726 , 0.78823537, 0.76470596]],\n",
       " \n",
       "         [[0.9568628 , 0.9607844 , 0.94117653],\n",
       "          [0.7411765 , 0.7294118 , 0.70980394],\n",
       "          [0.7725491 , 0.7568628 , 0.72156864],\n",
       "          ...,\n",
       "          [0.7568628 , 0.7137255 , 0.6901961 ],\n",
       "          [0.80392164, 0.76470596, 0.7294118 ],\n",
       "          [0.83921576, 0.8000001 , 0.76470596]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.69411767, 0.67058825, 0.6784314 ],\n",
       "          [0.227451  , 0.20392159, 0.21176472],\n",
       "          [0.20784315, 0.18431373, 0.19215688],\n",
       "          ...,\n",
       "          [0.6431373 , 0.5372549 , 0.454902  ],\n",
       "          [0.63529414, 0.53333336, 0.4431373 ],\n",
       "          [0.76470596, 0.6627451 , 0.5647059 ]],\n",
       " \n",
       "         [[0.7137255 , 0.6901961 , 0.69803923],\n",
       "          [0.26666668, 0.24313727, 0.2509804 ],\n",
       "          [0.23529413, 0.21176472, 0.21960786],\n",
       "          ...,\n",
       "          [0.654902  , 0.54901963, 0.47450984],\n",
       "          [0.64705884, 0.5411765 , 0.45882356],\n",
       "          [0.73333335, 0.6313726 , 0.5411765 ]],\n",
       " \n",
       "         [[0.74509805, 0.72156864, 0.7294118 ],\n",
       "          [0.14901961, 0.1254902 , 0.13333334],\n",
       "          [0.16862746, 0.14509805, 0.15294118],\n",
       "          ...,\n",
       "          [0.74509805, 0.6392157 , 0.57254905],\n",
       "          [0.7254902 , 0.61960787, 0.5529412 ],\n",
       "          [0.69411767, 0.5882353 , 0.5137255 ]]],\n",
       " \n",
       " \n",
       "        [[[0.10980393, 0.12156864, 0.08627451],\n",
       "          [0.14901961, 0.16078432, 0.1254902 ],\n",
       "          [0.14901961, 0.16078432, 0.1254902 ],\n",
       "          ...,\n",
       "          [0.6039216 , 0.6627451 , 0.57254905],\n",
       "          [0.6039216 , 0.6627451 , 0.57254905],\n",
       "          [0.59607846, 0.6666667 , 0.5803922 ]],\n",
       " \n",
       "         [[0.05490196, 0.06666667, 0.03137255],\n",
       "          [0.09019608, 0.10196079, 0.06666667],\n",
       "          [0.09019608, 0.10196079, 0.06666667],\n",
       "          ...,\n",
       "          [0.6039216 , 0.6627451 , 0.57254905],\n",
       "          [0.6039216 , 0.6627451 , 0.57254905],\n",
       "          [0.59607846, 0.6666667 , 0.5803922 ]],\n",
       " \n",
       "         [[0.05882353, 0.07058824, 0.03529412],\n",
       "          [0.09411766, 0.10588236, 0.07058824],\n",
       "          [0.09411766, 0.10588236, 0.07058824],\n",
       "          ...,\n",
       "          [0.6       , 0.65882355, 0.5686275 ],\n",
       "          [0.6       , 0.65882355, 0.5686275 ],\n",
       "          [0.6       , 0.65882355, 0.5686275 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.45098042, 0.5294118 , 0.48627454],\n",
       "          [0.45882356, 0.5372549 , 0.49411768],\n",
       "          [0.45882356, 0.5372549 , 0.49411768],\n",
       "          ...,\n",
       "          [0.4784314 , 0.5019608 , 0.36862746],\n",
       "          [0.4784314 , 0.5019608 , 0.36862746],\n",
       "          [0.47450984, 0.49803925, 0.3647059 ]],\n",
       " \n",
       "         [[0.46274513, 0.5411765 , 0.49803925],\n",
       "          [0.47058827, 0.54901963, 0.5058824 ],\n",
       "          [0.47058827, 0.54901963, 0.5058824 ],\n",
       "          ...,\n",
       "          [0.48627454, 0.50980395, 0.37647063],\n",
       "          [0.48627454, 0.50980395, 0.37647063],\n",
       "          [0.48235297, 0.5058824 , 0.37254903]],\n",
       " \n",
       "         [[0.45098042, 0.5294118 , 0.48627454],\n",
       "          [0.45098042, 0.5294118 , 0.48627454],\n",
       "          [0.45098042, 0.5294118 , 0.48627454],\n",
       "          ...,\n",
       "          [0.4901961 , 0.5137255 , 0.3803922 ],\n",
       "          [0.4901961 , 0.5137255 , 0.3803922 ],\n",
       "          [0.48627454, 0.50980395, 0.37647063]]]], dtype=float32),\n",
       " array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(valid_flow_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b1e82f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Dropout, MaxPooling2D, GlobalAveragePooling2D, Activation\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "def Create_Model(model_name = 'DG_CT_Similar'):\n",
    "    input_tensor = Input(shape = (224, 224, 3))\n",
    "    base_model = VGG16(input_tensor = input_tensor, include_top = False, weights = 'imagenet')\n",
    "    \n",
    "    base_md = base_model.output\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(base_md)\n",
    "    x = Dense(50, activation = 'relu')(x)\n",
    "    output = Dense(2, activation = 'softmax', name = 'Output')(x)\n",
    "    \n",
    "    model = Model(inputs = input_tensor, outputs = output)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "513f9d4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_10  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 50)                25650     \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 14,740,440\n",
      "Trainable params: 14,740,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\wongi\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "126/126 [==============================] - 55s 338ms/step - loss: 3.5741 - accuracy: 0.5142 - val_loss: 0.6871 - val_accuracy: 0.5440\n",
      "Epoch 2/40\n",
      "126/126 [==============================] - 43s 342ms/step - loss: 0.6909 - accuracy: 0.5309 - val_loss: 0.6712 - val_accuracy: 0.5553\n",
      "Epoch 3/40\n",
      "126/126 [==============================] - 41s 328ms/step - loss: 0.6754 - accuracy: 0.5655 - val_loss: 0.6738 - val_accuracy: 0.5047\n",
      "Epoch 4/40\n",
      "126/126 [==============================] - 42s 334ms/step - loss: 0.6652 - accuracy: 0.5810 - val_loss: 0.6509 - val_accuracy: 0.6121\n",
      "Epoch 5/40\n",
      "126/126 [==============================] - 41s 321ms/step - loss: 0.6362 - accuracy: 0.6215 - val_loss: 0.6203 - val_accuracy: 0.6552\n",
      "Epoch 6/40\n",
      "126/126 [==============================] - 40s 316ms/step - loss: 0.6434 - accuracy: 0.6234 - val_loss: 0.6688 - val_accuracy: 0.5878\n",
      "Epoch 7/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.6303 - accuracy: 0.6447 - val_loss: 0.6172 - val_accuracy: 0.6502\n",
      "Epoch 8/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.5667 - accuracy: 0.7038 - val_loss: 0.5572 - val_accuracy: 0.7089\n",
      "Epoch 9/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.5462 - accuracy: 0.7210 - val_loss: 0.5153 - val_accuracy: 0.7364\n",
      "Epoch 10/40\n",
      "126/126 [==============================] - 39s 313ms/step - loss: 0.5049 - accuracy: 0.7564 - val_loss: 0.4687 - val_accuracy: 0.7808\n",
      "Epoch 11/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.4459 - accuracy: 0.7946 - val_loss: 0.3996 - val_accuracy: 0.8326\n",
      "Epoch 12/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.3982 - accuracy: 0.8244 - val_loss: 0.3873 - val_accuracy: 0.8332\n",
      "Epoch 13/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.3614 - accuracy: 0.8403 - val_loss: 0.2865 - val_accuracy: 0.8844\n",
      "Epoch 14/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.3200 - accuracy: 0.8601 - val_loss: 0.2891 - val_accuracy: 0.8763\n",
      "Epoch 15/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.2620 - accuracy: 0.8911 - val_loss: 0.1959 - val_accuracy: 0.9269\n",
      "Epoch 16/40\n",
      "126/126 [==============================] - 40s 314ms/step - loss: 0.2429 - accuracy: 0.9008 - val_loss: 0.1652 - val_accuracy: 0.9363\n",
      "Epoch 17/40\n",
      "126/126 [==============================] - 38s 303ms/step - loss: 0.2071 - accuracy: 0.9156 - val_loss: 0.1884 - val_accuracy: 0.9244\n",
      "Epoch 18/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.1685 - accuracy: 0.9338 - val_loss: 0.1279 - val_accuracy: 0.9538\n",
      "Epoch 19/40\n",
      "126/126 [==============================] - 40s 314ms/step - loss: 0.1418 - accuracy: 0.9442 - val_loss: 0.1501 - val_accuracy: 0.9332\n",
      "Epoch 20/40\n",
      "126/126 [==============================] - 39s 313ms/step - loss: 0.1283 - accuracy: 0.9504 - val_loss: 0.2847 - val_accuracy: 0.8776\n",
      "Epoch 21/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.1706 - accuracy: 0.9309 - val_loss: 0.1076 - val_accuracy: 0.9644\n",
      "Epoch 22/40\n",
      "126/126 [==============================] - 39s 313ms/step - loss: 0.1381 - accuracy: 0.9435 - val_loss: 0.1443 - val_accuracy: 0.9382\n",
      "Epoch 23/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.1232 - accuracy: 0.9515 - val_loss: 0.0691 - val_accuracy: 0.9763\n",
      "Epoch 24/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.0773 - accuracy: 0.9699 - val_loss: 0.0703 - val_accuracy: 0.9706\n",
      "Epoch 25/40\n",
      "126/126 [==============================] - 40s 319ms/step - loss: 0.0784 - accuracy: 0.9711 - val_loss: 0.0192 - val_accuracy: 0.9944\n",
      "Epoch 26/40\n",
      "126/126 [==============================] - 40s 314ms/step - loss: 0.0748 - accuracy: 0.9709 - val_loss: 0.0504 - val_accuracy: 0.9806\n",
      "Epoch 27/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.0500 - accuracy: 0.9818 - val_loss: 0.0476 - val_accuracy: 0.9800\n",
      "Epoch 28/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.0687 - accuracy: 0.9736 - val_loss: 0.0535 - val_accuracy: 0.9825\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 29/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.0178 - accuracy: 0.9948 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 30/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 8.5720e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 8.0478e-04 - accuracy: 0.9999 - val_loss: 2.1475e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/40\n",
      "126/126 [==============================] - 40s 314ms/step - loss: 2.0342e-04 - accuracy: 1.0000 - val_loss: 1.1112e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 1.2213e-04 - accuracy: 1.0000 - val_loss: 6.2625e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/40\n",
      "126/126 [==============================] - 39s 313ms/step - loss: 7.4530e-05 - accuracy: 1.0000 - val_loss: 3.9003e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/40\n",
      "126/126 [==============================] - 39s 313ms/step - loss: 5.1099e-05 - accuracy: 1.0000 - val_loss: 2.5438e-05 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 36/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 3.8725e-05 - accuracy: 1.0000 - val_loss: 2.3970e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/40\n",
      "126/126 [==============================] - 40s 314ms/step - loss: 3.6431e-05 - accuracy: 1.0000 - val_loss: 2.2711e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/40\n",
      "126/126 [==============================] - 40s 314ms/step - loss: 3.4413e-05 - accuracy: 1.0000 - val_loss: 2.1182e-05 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 39/40\n",
      "126/126 [==============================] - 39s 313ms/step - loss: 3.2689e-05 - accuracy: 1.0000 - val_loss: 2.0850e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/40\n",
      "126/126 [==============================] - 40s 313ms/step - loss: 3.2265e-05 - accuracy: 1.0000 - val_loss: 2.0558e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dg_cat_similar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16044/2964102644.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_flow_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrlp_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mels_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_flow_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdg_cat_similar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dg_cat_similar' is not defined"
     ]
    }
   ],
   "source": [
    "model = Create_Model()\n",
    "model.compile(optimizer = Adam(learning_rate = 0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "rlp_cb = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, verbose = 1, patience = 3, mode = 'min')\n",
    "els_cb = EarlyStopping(monitor = 'val_loss', patience= 10, restore_best_weights= True, mode = 'min', verbose = 1)\n",
    "# mlc_cb = ModelCheckpoint(filepath = '/{epoch:02d}-{val_loss:.2f}.hdf5', monitor= 'val_loss', patience = 3, save_best_only= True)\n",
    "\n",
    "history = model.fit_generator(train_flow_gen, epochs = 40, callbacks = [rlp_cb, els_cb], verbose = 1, validation_data = valid_flow_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "157ff19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dg_cat_similar', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac2c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b06642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e9b5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e11f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832646b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72491eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11118028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
