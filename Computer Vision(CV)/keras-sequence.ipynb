{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Making DataFrame about Meta Information","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\ndef make_catndog_dataframe():\n    paths = []    # 경로\n    dataset_div = []\n    label_div = []\n    \n    for dirname, _, filenames in os.walk('/kaggle/input/cat-and-dog'):\n        for filename in filenames:\n            if '.jpg' in filename:\n                file_path = dirname + '/' + filename              \n                paths.append(file_path)\n                \n                if '/training_set/' in file_path:\n                    dataset_div.append('train')\n                elif '/test_set/' in file_path:\n                    dataset_div.append('test')\n                else:\n                    dataset_div.append('N/A')\n                \n                if 'dogs' in file_path:\n                    label_div.append('DOG')\n                elif 'cats' in file_path:\n                    label_div.append('CAT')\n                else:\n                    label_div.append('N/A')\n\n    data_df = pd.DataFrame({'path' : paths, 'dataset' : dataset_div , 'label' : label_div})\n    return data_df\n","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:33:05.939527Z","iopub.execute_input":"2022-01-09T15:33:05.940012Z","iopub.status.idle":"2022-01-09T15:33:05.949762Z","shell.execute_reply.started":"2022-01-09T15:33:05.939971Z","shell.execute_reply":"2022-01-09T15:33:05.948822Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', 200)\ndata_df = make_catndog_dataframe()\ndata_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:33:06.376556Z","iopub.execute_input":"2022-01-09T15:33:06.376882Z","iopub.status.idle":"2022-01-09T15:33:06.461284Z","shell.execute_reply.started":"2022-01-09T15:33:06.376850Z","shell.execute_reply":"2022-01-09T15:33:06.459934Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Making Sequence Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import Sequence\nimport sklearn\nimport cv2\n\nBatch_Size = 64\nImage_Size = 224\n\nclass CnD_Dataset(Sequence):\n    \n    def __init__(self, image_filenames, labels, batch_size = Batch_Size, augmentor = None, shuffle = False):\n        self.image_filenames = image_filenames\n        self.labels = labels\n        self.batch_size = batch_size\n        self.augmentor = augmentor\n        self.shuffle = shuffle\n        if self.shuffle:\n            # self.on_epoch_end()\n            pass\n        \n        \n    def __len__(self):\n        return int(np.ceil(len(self.labels) / self.batch_size))\n    \n    def __getitem__(self, index):\n        # Batch_Size 단위로 image_array, label_array 데이터를 가져와서 변환한뒤 다시 반환을 합니다.\n        \n        # index는 몇번쨰 batch인지를 나타냅니다.\n        image_name_batch = self.image_filenames[index*self.batch_size:(index + 1)*self.batch_size]\n        if self.labels is not None:\n            label_batch = self.labels[index*self.batch_size:(index + 1)*self.batch_size]\n        \n        # 만약에 Albumentations에 관한 내용이 전해진다면, 적용해야 합니다.\n        image_batch = np.zeros((image_name_batch.shape[0], Image_Size, Image_Size, 3))\n        for image_index in range(image_name_batch.shape[0]):\n            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n            image = cv2.resize(image, (Image_Size, Image_Size))\n            if self.augmentor is not None:\n                image = self.augmentor(image = image)['image']\n            \n#             image = image / 255.0  if you want Scaling(0 ~ 1)\n            \n            image_batch[image_index] = image\n        \n        return image_batch, label_batch\n    \n    def on_epoch_end(self):\n        if(self.shuffle):\n            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames, self.labels)\n        else:\n            pass","metadata":{"execution":{"iopub.status.busy":"2022-01-09T16:09:09.594084Z","iopub.execute_input":"2022-01-09T16:09:09.594411Z","iopub.status.idle":"2022-01-09T16:09:09.607782Z","shell.execute_reply.started":"2022-01-09T16:09:09.594373Z","shell.execute_reply":"2022-01-09T16:09:09.606729Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\ntrain_df = data_df[data_df['dataset'] == 'train']\ntest_df = data_df[data_df['dataset'] == 'test']\n\ntrain_image_filenames = train_df['path'].values\ntrain_image_labels = train_df['label'].values\n\ncnd_augmentator = A.Compose([\n    A.HorizontalFlip(p = 0.7),\n    A.VerticalFlip(p = 0.7),\n    A.ShiftScaleRotate(p = 0.7)\n])\n\ncnd_ds = CnD_Dataset(train_image_filenames, train_image_labels, augmentor = cnd_augmentator)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T16:04:41.065607Z","iopub.execute_input":"2022-01-09T16:04:41.066235Z","iopub.status.idle":"2022-01-09T16:04:41.079942Z","shell.execute_reply.started":"2022-01-09T16:04:41.066181Z","shell.execute_reply":"2022-01-09T16:04:41.079210Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"image_batch = next(iter(cnd_ds))[0]\nlabel_batch = next(iter(cnd_ds))[1]\nprint(image_batch.shape, label_batch.shape)\nprint(image_batch[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-09T16:05:42.077958Z","iopub.execute_input":"2022-01-09T16:05:42.078295Z","iopub.status.idle":"2022-01-09T16:05:43.510770Z","shell.execute_reply.started":"2022-01-09T16:05:42.078259Z","shell.execute_reply":"2022-01-09T16:05:43.509737Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_grid_images(images_batch, ncols = 4, title = None):\n    figure, axs = plt.subplots(figsize = (22, 4), nrows = 1, ncols = ncols)\n    for i in range(ncols):\n        axs[i].imshow(np.array(images_batch[i], dtype = 'int32'))\n        axs[i].axis('off')\n        axs[i].set_title(title[i])\n\nshow_grid_images(image_batch, ncols = 4, title = 'augmented' + label_batch)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T16:08:27.473411Z","iopub.execute_input":"2022-01-09T16:08:27.473735Z","iopub.status.idle":"2022-01-09T16:08:27.955569Z","shell.execute_reply.started":"2022-01-09T16:08:27.473700Z","shell.execute_reply":"2022-01-09T16:08:27.951014Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}