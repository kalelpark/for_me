{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled30.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmFLqUpkGN5M"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.layers import Dense, Flatten, Embedding\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import GRU, LSTM, SimpleRNN\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = 10000\n",
        "max_len = 500\n",
        "(train_data, train_label), (test_data, test_label) = imdb.load_data(num_words = num_words)\n",
        "pad_train_data = pad_sequences(train_data)\n",
        "pad_test_data = pad_sequences(test_data)\n",
        "\n",
        "model1 = Sequential(Embedding(input_dim = num_words,))\n",
        "model1.add(SimpleRNN(32))\n",
        "model1.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model1.compile(optimizer = 'RMSprop', loss = 'binary_crossentropy', metrics = 'acc')\n",
        "model1.summary()\n",
        "\n",
        "# history1 = model1.fit(pad_train_data, train_label, validation_split = 0.2, epochs = 30, batch_size = 128)"
      ],
      "metadata": {
        "id": "BFh1wDP2GSQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = model1.fit(pad_train_data, train_label, validation_split = 0.2, epochs = 10, batch_size = 128)"
      ],
      "metadata": {
        "id": "V7tjVA5MHCVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Embedding(input_dim = num_words, output_dim = 32))\n",
        "model2.add(LSTM(32, return_sequences = True))\n",
        "model2.add(Dense(1, activation = 'sigmoid'))\n",
        "model2.compile(optimizer = 'RMSprop', loss = 'binray_crossentropy', metrics = 'acc')\n",
        "model2.summary()\n",
        "\n",
        "history2 = model2.fit(pad_train_data, train_label, validation_split = 0.2, epochs = 10, batch_size = 128)"
      ],
      "metadata": {
        "id": "_zUjM6bkGVD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Sequential()\n",
        "\n",
        "model3.add(Embedding(input_dim = num_words, output_dim = 32))\n",
        "model3.add(GRU(32, return_sequences = True))\n",
        "model3.add(Dense(1, activation = 'sigmoid'))\n",
        "model3.compile(optimizer = 'RMSprop', loss = 'binray_crossentropy', metrics = 'acc')\n",
        "model3.summary()\n",
        "\n",
        "history3 = model3.fit(pad_train_data, train_label, validation_split = 0.2, epochs = 10, batch_size = 128)"
      ],
      "metadata": {
        "id": "Ukt3PoHJGWcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = Sequential()\n",
        "\n",
        "model4.add(Embedding(input_dim = num_words, output_dim = 32))\n",
        "model4.add(Conv1D(32,7, activation = 'relu'))\n",
        "model4.add(Dense(1, activation = 'sigmoid'))\n",
        "model4.compile(optimizer = 'RMSprop', loss = 'binray_crossentropy', metrics = 'acc')\n",
        "model4.summary()\n",
        "\n",
        "history4 = model4.fit(pad_train_data, train_label, validation_split = 0.2, epochs = 30, batch_size = 128)"
      ],
      "metadata": {
        "id": "ECEi_bCjGXoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "use_len = history1.history['loss']\n",
        "plt.plot(range(use_len), history1.history['val_loss'], c = 'r' , label = 'SimpleRNN')\n",
        "plt.plot(range(use_len), history2.history['val_loss'], c = 'g' , label = 'LSTM')\n",
        "plt.plot(range(use_len), history3.history['val_loss'], c = 'b' , label = 'GRU')\n",
        "plt.plot(range(use_len), history4.history['val_loss'], c = 'y' , label = 'Conv1D')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(use_len), history1.history['val_acc'], c = 'r' , label = 'SimpleRNN')\n",
        "plt.plot(range(use_len), history2.history['val_acc'], c = 'g' , label = 'LSTM')\n",
        "plt.plot(range(use_len), history3.history['val_acc'], c = 'b' , label = 'GRU')\n",
        "plt.plot(range(use_len), history4.history['val_acc'], c = 'y' , label = 'Conv1D')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tw98EhqEGgI6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}