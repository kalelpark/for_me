{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c3ccc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c\\.conda\\envs\\pytorch\\lib\\site-packages\\keras\\backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import inception_v3\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# 모델을 훈련하지 않습니다., 훈련 연산을 비활성화\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "model = inception_v3.InceptionV3(weights = 'imagenet',\n",
    "                                include_top = False)\n",
    "\n",
    "# 손실 계산 여러 층에 있는 모든 필터 활성화를 동시 시행\n",
    "# 어떤 층들을 선택했는지에 따라 만들어내는 시각요소에 큰 영향을 끼칩니다,\n",
    "\n",
    "# 층 이름과 계수를 매핑한 딕셔너리, 최대화 하려는 손실에 층의 활성화가 기여할 양을 정합니다.\n",
    "layer_contributions = {\n",
    "    'mixed2':0.2,\n",
    "    'mixed3':3.,\n",
    "    'mixed4':2.,\n",
    "    'mixed5':5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00cf194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 텐서 정의\n",
    "# L2 노름의 가중치 합\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "# loss = K.variable(0.)\n",
    "for layer_name in layer_contributions:\n",
    "    coeff = layer_contributions[layer_name]\n",
    "    # 층의 출력층 얻기\n",
    "    activation = layer_dict[layer_name].output \n",
    "    \n",
    "    scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
    "    # 층 특성의 L2 노름 제곱을 손실에 추가합니다. \n",
    "    loss =   K.variable(0.) + (coeff * K.sum(K.square(activation[:, 2: -2, 2:-2, :])) / scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eadaf7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dream = model.input  # 이미지 저장\n",
    "\n",
    "grads = K.gradients(loss, dream)[0]  # 손실에 대한 딥드림 이미지의 그레디언트 계산\n",
    "\n",
    "grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)    # 그레디언트 정규화\n",
    "# 손실과 gradient 값을 계산할 케라스 함수 생성\n",
    "outputs = [loss , grads]\n",
    "fetch_loss_and_grads = K.function([dream], outputs)\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    outs = fetch_loss_and_grads([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    return loss_value, grad_values\n",
    "\n",
    "# 경사 상승법 여러번 반복\n",
    "def gradient_ascent(x, iterations, step, max_loss = None):\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print(i, '번째 손실 : ', loss_value)\n",
    "        x += step * grad_values\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6503eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def resize_img(img, size):\n",
    "    img = np.copy(img)\n",
    "    factors = (1,\n",
    "              float(size[0]) / img.shape[1],\n",
    "              float(size[1]) / img.shape[2],\n",
    "                   1)\n",
    "    return scipy.ndimage.zoom(img, factors, order = 1)\n",
    "\n",
    "def save_img(img, fname):\n",
    "    pil_img = deprocess_image(np.copy(img))\n",
    "    image.save_img(fname, pil_img)\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "    \n",
    "def deprocess_image(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "    \n",
    "    x /= 2.\n",
    "    x += 0.5\n",
    "    x *= 255.\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89069a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리할 이미지 크기 (250, 250)\n",
      "0 번째 손실 :  0.38168335\n",
      "1 번째 손실 :  0.58073276\n",
      "2 번째 손실 :  0.80944896\n",
      "3 번째 손실 :  1.0608652\n",
      "4 번째 손실 :  1.3113792\n",
      "5 번째 손실 :  1.6232666\n",
      "6 번째 손실 :  2.023442\n",
      "7 번째 손실 :  2.513495\n",
      "8 번째 손실 :  2.9592946\n",
      "9 번째 손실 :  3.6489203\n",
      "10 번째 손실 :  4.356871\n",
      "11 번째 손실 :  4.6516924\n",
      "12 번째 손실 :  5.6578035\n",
      "13 번째 손실 :  6.341509\n",
      "14 번째 손실 :  7.1342974\n",
      "15 번째 손실 :  7.8280973\n",
      "16 번째 손실 :  8.785484\n",
      "17 번째 손실 :  9.337323\n",
      "처리할 이미지 크기 (250, 250)\n",
      "처리할 이미지 크기 (350, 350)\n",
      "0 번째 손실 :  0.7656622\n",
      "1 번째 손실 :  1.8136775\n",
      "2 번째 손실 :  2.9394631\n",
      "3 번째 손실 :  3.965658\n",
      "4 번째 손실 :  5.1302085\n",
      "5 번째 손실 :  6.3761024\n",
      "6 번째 손실 :  7.8313046\n",
      "7 번째 손실 :  8.751801\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "step = 0.01\n",
    "num_octave = 3\n",
    "octave_scale = 1.4\n",
    "iterations = 20\n",
    "\n",
    "max_loss = 10\n",
    "\n",
    "base_image_path = './original_photo_deep_dream.jpg'\n",
    "img = preprocess_image(base_image_path)\n",
    "\n",
    "original_shape = img.shape[1:3]\n",
    "succesive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** 1))\n",
    "                  for dim in original_shape])\n",
    "    succesive_shapes.append(shape)\n",
    "\n",
    "succesive_shapes = succesive_shapes[::-1]\n",
    "\n",
    "original_img = np.copy(img)\n",
    "shrunk_original_img = resize_img(img, succesive_shapes[0])\n",
    "\n",
    "for shape in succesive_shapes:\n",
    "    print('처리할 이미지 크기', shape)\n",
    "    img = resize_img(img, shape)\n",
    "    img = gradient_ascent(img,\n",
    "                         iterations = iterations,\n",
    "                         step = step,\n",
    "                         max_loss = max_loss)\n",
    "    \n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
    "    same_size_original = resize_img(original_img, shape)\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "    \n",
    "    img += lost_detail\n",
    "    shrunk_original_img = resize_img(original_img, shape)\n",
    "    save_img(img , fname = 'dream_at_scale_' + str(shape) + '.png')\n",
    "\n",
    "save_img(img, fname = './final_dream.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c166c197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2000fe93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb64100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad64ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c652f04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ef86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07c6872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ccd74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a8ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be795e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b21606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d0c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26da52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430ff21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f069ad2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b66c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0ae8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6cc7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e89c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde7dc57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7afffd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8572d2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d8a3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7fceab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416dcd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8d5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b317b9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae59d09f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0017409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65a7134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5217d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec268ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0124dcc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805dc09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b8395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
